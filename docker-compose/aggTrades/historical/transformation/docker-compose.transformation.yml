version: "3.8"

networks:
  spark-network:
    driver: bridge

volumes:
  spark-logs:
  spark-work:
  spark-config:
  spark-events: # Adding a volume for spark-events

services:
  spark-master:
    build:
      context: ./../../../..
      dockerfile: docker/aggTrades/historical/transformation/Dockerfile
    container_name: spark-master
    hostname: spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - spark-network
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_EVENTLOG_DIR=/tmp/spark-events
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/tmp/spark-events
    volumes:
      - spark-logs:/opt/bitnami/spark/logs
      - spark-events:/opt/bitnami/spark/spark-events # Ensure spark-events directory is mounted
      - ./spark-config/core-site.xml:/opt/bitnami/spark/conf/core-site.xml:ro
      - ./spark-config/log4j.properties:/opt/bitnami/spark/conf/log4j.properties:ro
      - ./spark-config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro

  spark-worker:
    build:
      context: ./../../../..
      dockerfile: docker/aggTrades/historical/transformation/Dockerfile
    hostname: spark-worker
    networks:
      - spark-network
    ports:
      - "8081-8090:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
    volumes:
      - spark-work:/opt/bitnami/spark/work
      - spark-logs:/opt/bitnami/spark/logs
      - spark-events:/opt/bitnami/spark/spark-events
      - ./spark-config/core-site.xml:/opt/bitnami/spark/conf/core-site.xml:ro
      - ./spark-config/log4j.properties:/opt/bitnami/spark/log4j.properties:ro
      - ./spark-config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro

  pyspark-app:
    build:
      context: ./../../../..
      dockerfile: docker/aggTrades/historical/transformation/Dockerfile
    container_name: transformation-pyspark-app
    hostname: transformation-pyspark-app
    env_file: ./../../../../.env
    user: root
    networks:
      - spark-network
    depends_on:
      - spark-master
      - spark-worker
    volumes:
      - spark-logs:/opt/bitnami/spark/logs
      - spark-events:/opt/bitnami/spark/spark-events
      - ./spark-config/core-site.xml:/opt/bitnami/spark/conf/core-site.xml:ro
      #- ./spark-config/log4j.properties:/opt/bitnami/spark/conf/log4j.properties:ro
      - ./spark-config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro
      - ./../../../../cores/aggTrades/historical/transformation/src:/opt/bitnami/spark/app:ro
    command:
      [
        "/opt/bitnami/spark/bin/spark-submit",
        "--master",
        "spark://spark-master:7077",
        "--deploy-mode",
        "client",
        "/opt/bitnami/spark/app/scheduler.py",
      ]
